# ğŸ—ï¸ ARCHITECTURE - dots.ocr-ultimate

## ğŸ“‹ Table of Contents
- [Overview](#overview)
- [Project Structure](#project-structure)
- [Core Components](#core-components)
- [API Layer](#api-layer)
- [Training Infrastructure](#training-infrastructure)
- [Deployment](#deployment)
- [Data Flow](#data-flow)
- [Technology Stack](#technology-stack)

---

## ğŸ¯ Overview

**dots.ocr-ultimate** is a unified fork combining the best features from multiple community forks of the original dots.ocr project. It provides a complete ecosystem for document OCR with multiple deployment options and training capabilities.

### Design Principles

1. **Modularity**: Each component can be used independently
2. **Flexibility**: Multiple API options for different use cases
3. **Scalability**: From single GPU to enterprise deployments
4. **Extensibility**: Easy to add new features and integrate updates

---

## ğŸ“ Project Structure

```
dots.ocr-ultimate/
â”‚
â”œâ”€â”€ ğŸ“¦ Core Model Layer
â”‚   â””â”€â”€ dots_ocr/              # Original dots.ocr implementation
â”‚       â”œâ”€â”€ model/             # Model implementations
â”‚       â”‚   â”œâ”€â”€ inference.py   # Inference logic
â”‚       â”‚   â””â”€â”€ layout_service.py  # PP-DocLayout integration (zihao)
â”‚       â”œâ”€â”€ parser.py          # Main parser interface
â”‚       â””â”€â”€ utils/
â”‚           â”œâ”€â”€ pdf_extractor.py   # Text extraction (zihao)
â”‚           â””â”€â”€ demo_utils/        # Utilities
â”‚
â”œâ”€â”€ ğŸŒ API Layer
â”‚   â”œâ”€â”€ simple/                # Flask REST API (am009)
â”‚   â”‚   â”œâ”€â”€ ocr_api_server.py  # Simple API server
â”‚   â”‚   â”œâ”€â”€ forward_exec.py    # Execution wrapper
â”‚   â”‚   â”œâ”€â”€ test_ocr_api.py    # API tests
â”‚   â”‚   â””â”€â”€ API_Documentation*.md
â”‚   â”‚
â”‚   â””â”€â”€ enterprise/            # FastAPI Enterprise (akcqhzdy)
â”‚       â””â”€â”€ app/
â”‚           â”œâ”€â”€ dotsocr_service.py  # Main service
â”‚           â””â”€â”€ utils/
â”‚               â”œâ”€â”€ configs.py         # Configuration
â”‚               â”œâ”€â”€ executor/          # Task execution
â”‚               â”‚   â”œâ”€â”€ job_executor_pool.py
â”‚               â”‚   â”œâ”€â”€ task_executor_pool.py
â”‚               â”‚   â””â”€â”€ ocr_task.py
â”‚               â”œâ”€â”€ pg_vector/         # PostgreSQL integration
â”‚               â”‚   â”œâ”€â”€ pg_vector.py
â”‚               â”‚   â””â”€â”€ table.py
â”‚               â”œâ”€â”€ storage.py         # OSS storage
â”‚               â”œâ”€â”€ tracing.py         # OpenTelemetry
â”‚               â”œâ”€â”€ redis.py           # Redis cache
â”‚               â””â”€â”€ hash.py            # MD5 utilities
â”‚
â”œâ”€â”€ ğŸ“ Training Infrastructure
â”‚   â””â”€â”€ training/              # Training suite (wjbmattingly)
â”‚       â”œâ”€â”€ train_simple.py          # Beginner-friendly training
â”‚       â”œâ”€â”€ train_dotsocr.py         # Advanced training + LoRA
â”‚       â”œâ”€â”€ create_training_data.py  # Data preparation
â”‚       â”œâ”€â”€ example_usage.py         # Examples
â”‚       â”œâ”€â”€ run_training.sh          # Automation scripts
â”‚       â”œâ”€â”€ test_training*.py        # Tests
â”‚       â”œâ”€â”€ config_training.yaml     # Config templates
â”‚       â””â”€â”€ README_*.md              # Documentation
â”‚
â”œâ”€â”€ ğŸ³ Deployment
â”‚   â””â”€â”€ deployment/
â”‚       â””â”€â”€ docker/            # Docker configs (am009)
â”‚           â”œâ”€â”€ Dockerfile
â”‚           â”œâ”€â”€ start.sh
â”‚           â”œâ”€â”€ daemon-start.sh
â”‚           â””â”€â”€ stop.sh
â”‚
â”œâ”€â”€ ğŸ“š Documentation
â”‚   â”œâ”€â”€ docs/
â”‚   â”‚   â”œâ”€â”€ ARCHITECTURE.md    # This file
â”‚   â”‚   â”œâ”€â”€ API_GUIDE.md       # API usage guide
â”‚   â”‚   â””â”€â”€ TRAINING_GUIDE.md  # Training guide
â”‚   â”‚
â”‚   â”œâ”€â”€ ULTIMATE_README.md     # Main README
â”‚   â”œâ”€â”€ requirements-unified.txt
â”‚   â””â”€â”€ PUSH_INSTRUCTIONS.md
â”‚
â”œâ”€â”€ ğŸ› ï¸ Tools & Utilities
â”‚   â”œâ”€â”€ tools/                 # Helper scripts
â”‚   â”œâ”€â”€ demo/                  # Demo applications
â”‚   â””â”€â”€ assets/                # Images and resources
â”‚
â””â”€â”€ ğŸ“‹ Configuration
    â”œâ”€â”€ requirements.txt       # Original requirements
    â”œâ”€â”€ requirements-unified.txt
    â”œâ”€â”€ setup.py
    â””â”€â”€ .gitignore
```

---

## ğŸ’ Core Components

### 1. Model Layer (`dots_ocr/`)

**Purpose**: Core OCR and layout parsing functionality

#### Key Files:

**`model/inference.py`**
- VLM inference using transformers
- Qwen2.5-VL based implementation
- Multi-modal input processing (images + text prompts)

**`model/layout_service.py`** *(from zihao branch)*
- PP-DocLayout-L integration
- Layout detection for structured PDFs
- Faster processing for text-based documents

**`parser.py`**
- Main interface for document parsing
- Handles images and PDFs
- Coordinates between OCR and layout detection

**`utils/pdf_extractor.py`** *(from zihao branch)*
- PyMuPDF (fitz) based text extraction
- Detects structured vs scanned PDFs
- Direct text extraction when available

#### Data Flow:

```
Input Document
    â†“
Parser (parser.py)
    â†“
â”œâ”€ Structured PDF? â†’ layout_service.py + pdf_extractor.py
â”‚                     (Fast path - no OCR needed)
â””â”€ Scanned/Image? â†’ inference.py (VLM OCR)
                     (Full OCR inference)
    â†“
Output (JSON/Markdown)
```

---

## ğŸŒ API Layer

### Option 1: Simple API (`api/simple/`)

**Source**: am009 fork  
**Technology**: Flask + Transformers  
**Best for**: Quick prototyping, single GPU, simple deployments

#### Architecture:

```
Client Request
    â†“
ocr_api_server.py (Flask)
    â†“
forward_exec.py (Execution wrapper)
    â†“
Transformers Model (dots_ocr)
    â†“
Response (JSON/Streaming)
```

#### Key Features:
- **Auto GPU Detection**: Automatically selects float32/float16/bfloat16
- **Multiple Input Formats**: Path, URL, Base64
- **Streaming Support**: For large documents
- **Processing Lock**: Single request at a time
- **Temporary File Management**: Auto-cleanup

#### Endpoints:
- `GET /health` - Health check
- `POST /ocr` - OCR processing

#### Configuration:
```python
# Environment variables
TORCH_DTYPE=auto  # or float32, float16, bfloat16

# Supports RTX 20xx (Turing) and newer
```

---

### Option 2: Enterprise API (`api/enterprise/`)

**Source**: akcqhzdy fork  
**Technology**: FastAPI + PostgreSQL + Redis + OpenTelemetry  
**Best for**: Production, high-load, enterprise deployments

#### Architecture:

```
Client Request
    â†“
FastAPI (dotsocr_service.py)
    â†“
Job Queue (job_executor_pool.py)
    â†“
â”œâ”€ Task Executor (task_executor_pool.py)
â”‚  â”œâ”€ OCR Task (ocr_task.py)
â”‚  â””â”€ Picture Description Task
â”‚      â†“
â”œâ”€ PostgreSQL (pg_vector/)
â”‚  â””â”€ Vector embeddings + metadata
â”‚      â†“
â”œâ”€ Redis (redis.py)
â”‚  â””â”€ Caching layer
â”‚      â†“
â”œâ”€ OSS Storage (storage.py)
â”‚  â””â”€ Distributed file storage
â”‚      â†“
â””â”€ OpenTelemetry (tracing.py)
   â””â”€ Distributed tracing

Response + Metrics
```

#### Components:

**1. Job Executor Pool**
```python
# Manages concurrent jobs
- Max concurrent jobs: configurable
- Queue management
- Retry logic with exponential backoff
- Job status tracking
```

**2. Task Executor Pool**
```python
# Manages OCR inference tasks
- Concurrent task limit
- Async execution
- Timeout management
- Performance metrics
```

**3. PostgreSQL + PGVector**
```python
# Document storage and search
- OCR results storage
- Vector embeddings
- MD5-based deduplication
- Query by similarity
```

**4. Redis Cache**
```python
# Performance optimization
- Result caching
- Session management
- Rate limiting support
```

**5. OpenTelemetry Tracing**
```python
# Monitoring and debugging
- Request tracing
- Performance profiling
- Error tracking
- SQLAlchemy instrumentation
- OpenAI API instrumentation
```

#### Endpoints:
- `POST /parse` - Parse documents
- `GET /token_usage` - Token statistics
- `GET /status` - Job status
- `GET /health` - Health check

#### Configuration:
```bash
# Required
POSTGRES_URL_NO_SSL_DEV=postgresql://user:pass@host/db
API_KEY=sk-your-openai-key

# Optional
OSS_ENDPOINT=https://oss.example.com
OSS_ACCESS_KEY_ID=your-key
OSS_ACCESS_KEY_SECRET=your-secret
OCR_INFERENCE_HOST=localhost
OCR_INFERENCE_PORT=8000
INTERN_VL_HOST=localhost
INTERN_VL_PORT=8001
NUM_WORKERS=4
CONCURRENT_OCR_TASK_LIMIT=2
CONCURRENT_DESCRIBE_PICTURE_TASK_LIMIT=1
API_TIMEOUT=300
DPI=200
TASK_RETRY_COUNT=3
```

---

## ğŸ“ Training Infrastructure

**Source**: wjbmattingly fork  
**Purpose**: Fine-tune dots.ocr on custom datasets

### Components:

#### 1. Data Preparation
```
PAGEXML + JPEG Files
    â†“
create_training_data.py
    â†“
Training JSONL Format
```

#### 2. Training Scripts

**`train_simple.py`** - Beginner-friendly
```python
# Features:
- Sensible defaults
- Simple CLI interface
- Progress tracking
- Weights & Biases integration
- Automatic checkpointing
```

**`train_dotsocr.py`** - Advanced
```python
# Features:
- Full parameter control
- LoRA support (parameter-efficient)
- Vision encoder freezing
- Mixed precision training (bf16/fp16)
- Custom learning rate scheduling
- Gradient accumulation
- DeepSpeed integration (optional)
```

#### 3. Training Strategies

**Strategy 1: Full Fine-tuning**
```bash
# Best results, requires ~24GB GPU
python training/train_simple.py \
  --data training_data.jsonl \
  --epochs 3 \
  --batch_size 1 \
  --learning_rate 2e-5
```

**Strategy 2: LoRA (Memory Efficient)**
```bash
# Good results, requires ~12GB GPU
python training/train_dotsocr.py \
  --train_data training_data.jsonl \
  --lora_training \
  --lora_rank 8 \
  --learning_rate 1e-4
```

**Strategy 3: Freeze Vision Encoder**
```bash
# Fast training, text-focused
python training/train_dotsocr.py \
  --train_data training_data.jsonl \
  --freeze_vision_encoder \
  --learning_rate 5e-5
```

### Training Pipeline:

```
Data Preparation
    â†“
create_training_data.py
    â†“
Training Data (JSONL)
    â†“
train_simple.py / train_dotsocr.py
    â†“
â”œâ”€ Model Loading (dots_ocr)
â”œâ”€ Data Loading & Processing
â”œâ”€ Training Loop
â”‚  â”œâ”€ Forward Pass
â”‚  â”œâ”€ Loss Calculation
â”‚  â”œâ”€ Backward Pass
â”‚  â””â”€ Optimizer Step
â”œâ”€ Validation (optional)
â”œâ”€ Checkpointing
â””â”€ Metrics Logging (W&B)
    â†“
Fine-tuned Model
```

---

## ğŸ³ Deployment

### Docker Configuration

**Source**: am009 fork  
**Purpose**: Containerized deployment

```dockerfile
# Base: NVIDIA CUDA image
FROM nvidia/cuda:11.8.0-cudnn8-runtime-ubuntu22.04

# Install Python + dependencies
RUN apt-get update && apt-get install -y python3.10

# Copy application
COPY . /DotsOCR

# Install dependencies
RUN pip install -r requirements-unified.txt

# Expose API port
EXPOSE 5000

# Start service
CMD ["/DotsOCR/start.sh"]
```

### Deployment Options:

#### 1. Docker Single Container
```bash
docker run -d --runtime=nvidia --gpus=all \
  -p 5000:5000 \
  dots.ocr-ultimate:latest
```

#### 2. Docker Compose (Multi-Service)
```yaml
version: '3.8'
services:
  dots-ocr:
    image: dots.ocr-ultimate
    runtime: nvidia
    environment:
      - TORCH_DTYPE=auto
  
  postgres:
    image: postgres:15
    environment:
      - POSTGRES_DB=dotsocr
  
  redis:
    image: redis:7
```

#### 3. Kubernetes (Scalable)
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: dots-ocr
spec:
  replicas: 3
  selector:
    matchLabels:
      app: dots-ocr
  template:
    spec:
      containers:
      - name: dots-ocr
        image: dots.ocr-ultimate
        resources:
          limits:
            nvidia.com/gpu: 1
```

---

## ğŸ”„ Data Flow Diagrams

### Simple API Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Client  â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
     â”‚ HTTP POST /ocr
     â”‚ {image, format, prompt}
     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Flask Server   â”‚
â”‚ (port 5000)     â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â”œâ”€ Health Check?
     â”‚  â””â†’ Return status
     â”‚
     â”œâ”€ Image Processing
     â”‚  â”œâ”€ Load from path/URL/base64
     â”‚  â””â”€ Create temp file if needed
     â”‚
     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Transformers Model   â”‚
â”‚ (dots_ocr)           â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â”œâ”€ Vision Encoder
     â”œâ”€ Language Model
     â””â”€ Generate Output
     â”‚
     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Response         â”‚
â”‚ - JSON/Stream    â”‚
â”‚ - Cleanup temps  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Enterprise API Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Client  â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
     â”‚ HTTP POST /parse
     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FastAPI Service     â”‚
â”‚ (dotsocr_service)   â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â”œâ”€ Check Redis Cache
     â”‚  â””â”€ Hit? â†’ Return cached
     â”‚
     â”œâ”€ Check PostgreSQL
     â”‚  â””â”€ MD5 exists? â†’ Return stored
     â”‚
     â”œâ”€ Create Job
     â”‚  â””â”€ Add to job_executor_pool
     â”‚
     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Job Executor Pool  â”‚
â”‚ (async workers)    â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â”œâ”€ Acquire processing lock
     â”œâ”€ Download from OSS (if needed)
     â”œâ”€ Create OCR tasks
     â”‚
     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Task Executor Pool   â”‚
â”‚ (OCR + Description)  â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â”œâ”€ OCR Task
     â”‚  â””â”€ Call dots_ocr model
     â”‚
     â”œâ”€ Picture Description
     â”‚  â””â”€ Call InternVL model
     â”‚
     â””â”€ Retry on failure
     â”‚
     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Result Processing  â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â”œâ”€ Save to PostgreSQL
     â”œâ”€ Cache in Redis
     â”œâ”€ Upload to OSS
     â”œâ”€ Log to OpenTelemetry
     â”‚
     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Response   â”‚
â”‚   + Metrics  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ Technology Stack

### Core Technologies

| Component | Technology | Version | Purpose |
|-----------|-----------|---------|---------|
| **ML Framework** | PyTorch | 2.0+ | Deep learning |
| **Model** | Qwen2.5-VL | 1.7B | Vision-Language Model |
| **Transformers** | HuggingFace | 4.54 | Model loading & inference |
| **Vision** | torchvision | latest | Image processing |
| **Acceleration** | flash-attn | 2.8.0 | Attention optimization |

### API Layer

| Component | Technology | Use Case |
|-----------|-----------|----------|
| **Simple API** | Flask 3.0+ | Quick prototyping |
| **Enterprise API** | FastAPI 0.100+ | Production |
| **Async Runtime** | uvicorn | ASGI server |
| **HTTP Client** | httpx | Async requests |

### Data Storage

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Vector DB** | PostgreSQL + PGVector | Document embeddings |
| **Cache** | Redis 5.0+ | Performance |
| **Object Storage** | S3-compatible (OSS) | Distributed files |
| **ORM** | SQLAlchemy 2.0 | Database abstraction |

### Monitoring

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Tracing** | OpenTelemetry | Distributed tracing |
| **Logging** | Loguru | Structured logging |
| **Metrics** | Custom + OTLP | Performance tracking |
| **Training** | Weights & Biases | Experiment tracking |

### Document Processing

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **PDF** | PyMuPDF (fitz) | Text extraction |
| **Layout** | PP-DocLayout-L | Structure detection |
| **OCR** | dots.ocr (VLM) | Image-to-text |

---

## ğŸ“Š Performance Characteristics

### Simple API
- **Latency**: ~2-5 seconds per page
- **Throughput**: 1 request at a time
- **Memory**: 6-12GB VRAM (depending on dtype)
- **Scalability**: Single instance

### Enterprise API
- **Latency**: ~2-5 seconds per page (parallel)
- **Throughput**: Configurable (NUM_WORKERS)
- **Memory**: Depends on concurrent tasks
- **Scalability**: Horizontal (multiple instances)

### Structured PDF (zihao)
- **Latency**: ~0.5-1 second per page (10x faster)
- **Throughput**: Limited by layout detection
- **Memory**: Minimal VRAM usage
- **Best for**: Born-digital PDFs

---

## ğŸ” Security Considerations

### API Security
- API key authentication (Enterprise)
- Rate limiting (via Redis)
- Input validation
- Temporary file cleanup

### Data Privacy
- No persistent storage of input images (Simple API)
- Optional OSS encryption
- PostgreSQL SSL support
- Audit logging

---

## ğŸ“ˆ Scalability Patterns

### Horizontal Scaling
```
Load Balancer
    â†“
â”œâ”€ dots-ocr-1 (GPU 0)
â”œâ”€ dots-ocr-2 (GPU 1)
â””â”€ dots-ocr-3 (GPU 2)
    â†“
Shared PostgreSQL + Redis
```

### Vertical Scaling
```
Single Server
â”œâ”€ Multiple GPU (CUDA_VISIBLE_DEVICES)
â”œâ”€ Concurrent workers
â””â”€ Task queues
```

---

## ğŸ”„ Update Strategy

### Staying Synchronized

```bash
# Fetch updates from original
git fetch upstream-original master

# Fetch from forks
git fetch am009 master
git fetch akcqhzdy master
git fetch wjbmattingly master

# Review changes
git log HEAD..upstream-original/master

# Merge selectively
git cherry-pick <commit-hash>
```

---

## ğŸ“š Further Reading

- [API Guide](API_GUIDE.md) - Detailed API documentation
- [Training Guide](TRAINING_GUIDE.md) - Training best practices
- [Deployment Guide](DEPLOYMENT_GUIDE.md) - Production deployment
- [Contributing](../CONTRIBUTING.md) - How to contribute

---

**Last Updated**: October 2025  
**Version**: Ultimate v1.0  
**Maintainer**: Community Fork


